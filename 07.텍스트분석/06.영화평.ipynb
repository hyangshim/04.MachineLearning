{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 영화 리뷰 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =pd.read_csv(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", sep='\\t')\n",
    "test_df =pd.read_csv(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 3) (50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                           document  label\n",
       "0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                  너무재밓었다그래서보는것을추천한다      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape,test_df.shape)\n",
    "train_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    5\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치가 있는지 확인\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149995, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측기 데이터 삭제\n",
    "train_df.dropna(how='any',inplace=True)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 데이터 확인\n",
    "train_df.document.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146182, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 데이터 제거\n",
    "train_df.drop_duplicates(subset=['document'],inplace=True)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    73342\n",
       "1    72840\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 분포\n",
    "train_df.label.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49157, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.dropna(how='any',inplace=True)\n",
    "test_df.drop_duplicates(subset=['document'],inplace=True)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    24711\n",
       "0    24446\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 텍스트 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 트레인 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아더빙진짜짜증나네요목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고초딩영화줄오버연기조차가볍지않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                 document  label\n",
       "0   9976970            아더빙진짜짜증나네요목소리      0\n",
       "1   3819312  흠포스터보고초딩영화줄오버연기조차가볍지않구나      1\n",
       "2  10265843        너무재밓었다그래서보는것을추천한다      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
    "train_df.document= train_df.document.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]','',regex=True).str.strip()\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "789"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영어 데이터 -->''만 남게됨 --->np.nan 으로 대체한 후 제거\n",
    "train_df.document.replace('',np.nan,inplace=True)\n",
    "train_df.document.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145393, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dropna(how='any',inplace=True)\n",
    "train_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트 데이터 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48852, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
    "test_df.document= test_df.document.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]','',regex=True).str.strip()\n",
    "test_df.document.replace('',np.nan,inplace=True)\n",
    "test_df.dropna(how='any',inplace=True)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/네이버영화리뷰_train_전처리완료.tsv',sep='\\t',index=False)\n",
    "test_df.to_csv('data/네이버영화리뷰_test_전처리완료.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 한글 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt =Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍지', '않구나']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text ='흠포스터보고초딩영화줄오버연기조차가볍지않구나'\n",
    "okt.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍다', '않다']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.morphs(text,stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "이\tVCP\t0.018279601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/불용어.txt') as st:\n",
    "    lines = st.readlines()\n",
    "print(len(lines))\n",
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =[]\n",
    "for line in lines:\n",
    "    word =line.split('\\t')[0]\n",
    "    stop_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이', '있', '하', '것', '들', '그', '되', '수', '이', '보']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words =[line.split('\\t')[0] for line in lines]\n",
    "stop_words[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 형태소 분석기를 돌려서 나온 결과에서 stop_words 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphs = okt.morphs(text,stem=True)\n",
    "clean_morphs = [word for word in morphs if word not in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'흠 포스터 보고 초딩 영화 줄 오버 연기 조차 가볍다 않다'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean_morphs 문자열로 만들어 주어야 CountVectorizer의 입력으로 사용할 수 있음\n",
    "clean_review =' '.join(clean_morphs)\n",
    "clean_review\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 리뷰 str\n",
    "\n",
    "형태소 분석기 list\n",
    "\n",
    "불용어 제거 list\n",
    "\n",
    "문자열로 변환 str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'흠 포스터 보고 초딩 영화 줄 오버 연기 조차 가볍다 않다'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review='흠 포스터 보고 초딩 영화 줄 오버 연기 조차 가볍다 않구다'\n",
    "morphs = okt.morphs(review,stem=True)\n",
    "clean_morph_review =' '.join([word for word in morphs if word not in stop_words])\n",
    "clean_morph_review"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train /test dataset 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\YONSAI\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:89\u001b[0m, in \u001b[0;36mOkt.morphs\u001b[1;34m(self, phrase, norm, stem)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmorphs\u001b[39m(\u001b[39mself\u001b[39m, phrase, norm\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, stem\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     87\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m [s \u001b[39mfor\u001b[39;00m s, t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos(phrase, norm\u001b[39m=\u001b[39;49mnorm, stem\u001b[39m=\u001b[39;49mstem)]\n",
      "File \u001b[1;32mc:\\Users\\YONSAI\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:71\u001b[0m, in \u001b[0;36mOkt.pos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"POS tagger.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mIn contrast to other classes in this subpackage,\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mthis POS tagger doesn't have a `flatten` option,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39m:param join: If True, returns joined sets of morph and tag.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m validate_phrase_inputs(phrase)\n\u001b[1;32m---> 71\u001b[0m tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjki\u001b[39m.\u001b[39;49mtokenize(\n\u001b[0;32m     72\u001b[0m             phrase,\n\u001b[0;32m     73\u001b[0m             jpype\u001b[39m.\u001b[39;49mjava\u001b[39m.\u001b[39;49mlang\u001b[39m.\u001b[39;49mBoolean(norm),\n\u001b[0;32m     74\u001b[0m             jpype\u001b[39m.\u001b[39;49mjava\u001b[39m.\u001b[39;49mlang\u001b[39m.\u001b[39;49mBoolean(stem))\u001b[39m.\u001b[39mtoArray()\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m join:\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tokens]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = []\n",
    "for review in train_df.document:\n",
    "    morphs = okt.morphs(review,stem=True)\n",
    "    clean_morph_review =' '.join([word for word in morphs if word not in stop_words])\n",
    "    X_train.append(clean_morph_review)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "X_train = []\n",
    "for review in tqdm(train_df.document):\n",
    "    morphs = okt.morphs(review, stem=True)\n",
    "    clean_morph_review = ' '.join([word for word in morphs if word not in stop_words])\n",
    "    X_train.append(clean_morph_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test =[]\n",
    "for review in test_df.document:\n",
    "    morphs = okt.morphs(review,stem=True)\n",
    "    clean_morph_review =' '.join([word for word in morphs if word not in stop_words])\n",
    "    X_test.append(clean_morph_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train =train_df.label.values\n",
    "y_test =test_df.label.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 피쳐 변환 + 모델 학습 /평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline =Pipeline([\n",
    "    ('cvect',CountVectorizer()),\n",
    "    ('nb',MultinomialNB())\n",
    "])\n",
    "%time pipeline.fit(X_train.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 실제 데이터 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews =[\n",
    "    '이 영화 개꿀쨈 ㅋㅋㅋ',\n",
    "    '이 영화 핵노잼 ㅠㅠㅠ',\n",
    "    '이딴게 영화냐 ㅉㅉ',\n",
    "    '감독 뭐하는 놈이냐?',\n",
    "    '와 개쩐다 정말 세계관 최강자들의 영화다'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 - 한글 이외의 문자는 공백으로 변환\n",
    "import re\n",
    "reviews =list(map(lambda s: re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',s),reviews))\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석 후 불용어 제거\n",
    "processed_reviews =[]\n",
    "for review in test_df.document:\n",
    "    morphs = okt.morphs(reviews,stem=True)\n",
    "    clean_morph_review =' '.join([word for word in morphs if word not in stop_words])\n",
    "    processed_reviews.append(clean_morph_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict(processed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict_proba(processed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
